{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from io import BytesIO\n",
    "from urllib2 import urlopen\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "\n",
    "from matplotlib.image import imread\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "hv.notebook_extension('bokeh', width=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this little demo we'll have a look at using the HoloViews DataFrame support and Bokeh backend to explore some real world data. This demo first appeared on [Philipp Rudiger's blog](http://philippjfr.com/blog/visualizing-earthquake-data-with-holoviews-and-bokeh/), but this official example will be kept up to date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we extract shape coordinates for the continents and countries from matplotlib's ``basemap`` toolkit and put them inside a ``Polygons`` and ``Contours`` Element respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basemap = Basemap()\n",
    "kdims = ['Longitude', 'Latitude']\n",
    "continents = hv.Polygons([poly.get_coords() for poly in basemap.landpolygons],\n",
    "                         group='Continents', kdims=kdims)\n",
    "countries  = hv.Contours([np.array(country) for path in basemap._readboundarydata('countries')\n",
    "                         for country in path if not isinstance(country, int)],\n",
    "                         group='Countries', kdims=kdims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally we can load an satellite image of earth. Unfortunately embedding large images in the notebook using bokeh quickly balloons the size of the notebook so we'll downsample by a factor of 5x here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = basemap.bluemarble()\n",
    "blue_marble = hv.RGB(np.flipud(img.get_array()[::5, ::5]),\n",
    "                     bounds=(-180, -90, 180, 90), kdims=kdims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we download a few months worth of earthquake data from the US Geological survey (USGS), which provides a convenient web API and read it into a pandas DataFrame. For a full reference of the USGS API [look here](http://earthquake.usgs.gov/fdsnws/event/1/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate a valid query to the USGS API and let pandas handle the loading and parsing of dates \n",
    "query = dict(starttime=\"2014-12-01\", endtime=\"2014-12-31\")\n",
    "query_string = '&'.join('{0}={1}'.format(k, v) for k, v in query.items())\n",
    "query_url = \"http://earthquake.usgs.gov/fdsnws/event/1/query.csv?\" + query_string\n",
    "df = pd.read_csv(BytesIO(urlopen(query_url).read()),\n",
    "                 parse_dates=['time'], index_col='time',\n",
    "                 infer_datetime_format=True)\n",
    "df['Date'] = [str(t)[:19] for t in df.index]\n",
    "\n",
    "# Pass the earthquake dataframe into the HoloViews Element\n",
    "earthquakes = hv.Points(df, kdims=['longitude', 'latitude'],\n",
    "                        vdims=['place', 'Date', 'depth', 'mag', 'rms'],\n",
    "                        group='Earthquakes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at what this data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And get a summary overview of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's almost 9,000 data points, which should be no problem to load and render in memory. In a future blog post we'll look at loading and dynamically displaying several years worth of data using dask out-of-memory DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Styling our plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define some style options, in particular we map the size and color of our points to the magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%output size=150\n",
    "%opts Overlay [width=800]\n",
    "%opts Points.Earthquakes [color_index=5 size_index=5 scaling_factor=1.5] (cmap='hot_r' size=1)\n",
    "%opts Polygons.Continents (color='k')\n",
    "%opts Contours.Countries (color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll overlay the earthquake data on top of the 'Blue Marble' image we loaded previous, we'll also enable the hover tool so we can access some more information on each point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%opts Points.Earthquakes [tools=['hover']]\n",
    "blue_marble * earthquakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Earthquakes by day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ``groupby`` we can ``split`` our DataFrame up by day and using ``datetime`` we can generate date strings which we'll use as keys in a ``HoloMap``, allowing us to visualize earthquakes for each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_df = df.groupby([df.index.year, df.index.month, df.index.day])\n",
    "daily_earthquakes = hv.HoloMap(kdims=['Date'])\n",
    "for date, data in daily_df:\n",
    "    date = str(dt.date(*date))\n",
    "    daily_earthquakes[date] = (continents * countries *\n",
    "                               hv.Points(data, kdims=['longitude', 'latitude'],\n",
    "                                         vdims=['mag'], group='Earthquakes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're trying this notebook out in a live notebook you can set:\n",
    "\n",
    "```python\n",
    "%output widgets='live'\n",
    "```\n",
    "\n",
    "here to update the data dynamically. Since we're embedding this data here we'll only display every third date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%output holomap='scrubber'\n",
    "%%opts Overlay [width=800] Points.Earthquakes [color_index=2 size_index=2] \n",
    "daily_earthquakes[::3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using some pandas magic we can also resample the data and smooth it a little bit to see the frequency of earthquakes over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%opts Curve [width=600] Spikes [spike_length=4] (line_width=0.1)\n",
    "df['count'] = 1\n",
    "hourly_counts = pd.rolling_mean(df.resample('3H', how='count'), 5).reset_index()\n",
    "hv.Curve(hourly_counts, kdims=['time'], vdims=['count']) *\\\n",
    "hv.Spikes(df.reset_index(), kdims=['time'], vdims=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update: Linked data and widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another feature I've been playing with is automatic sharing of the data across plots, which automatically allows linked brushing and selecting. Here's a first quick demo of what this can look like. The only thing we need to do when adding a linked Element such as a ``Table`` is to ensure it draws from the same ``DataFrame`` as the other Elements we want to link it with. Using the 'lasso_select' tool we can select only a subregion of points and watch our selection get highlighted in the Table. In reverse we can also highlight rows in the Table and watch our selection appear in the plot, even editing is allowed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%opts Points.Earthquakes [tools=['lasso_select']] Overlay [width=800 height=400] Table [width=800]\n",
    "(blue_marble * earthquakes + hv.Table(earthquakes.data, kdims=['Date', 'latitude', 'longitude'], vdims=['depth', 'mag'])).cols(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linking plots in this way is a very powerful way to explore high-dimensional data. Here we'll add an Overlay split into tabs plotting the magnitude, RMS and depth value against each other. By linking that with the familiar map, we can easily explore how the geographical location relates to these other values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%opts Points [height=250 width=400 tools=['lasso_select', 'box_select']] (unselected_color='indianred')\n",
    "%%opts Overlay [width=500 height=300] Overlay.Combinations [tabs=True]\n",
    "from itertools import combinations\n",
    "dim_combos = combinations(['mag', 'depth', 'rms'], 2)\n",
    "(blue_marble * earthquakes +\n",
    " hv.Overlay([hv.Points(earthquakes.data, kdims=[c1, c2], group='%s_%s' % (c1, c2))\n",
    "            for c1, c2 in dim_combos], group='Combinations')).cols(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for this demo."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
