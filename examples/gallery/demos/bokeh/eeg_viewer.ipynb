{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "549b47a4",
   "metadata": {},
   "source": [
    "This example demonstrates advanced visualization techniques using HoloViews with the Bokeh plotting backend. You'll learn how to:\n",
    "\n",
    "1. Display multiple timeseries in a single plot using `subcoordinate_y`.\n",
    "2. Normalize the timeseries per *group*.\n",
    "3. Create and link a minimap to the main plot with `RangeToolLink`.\n",
    "\n",
    "Specifically, we'll simulate [Electroencephalography](https://en.wikipedia.org/wiki/Electroencephalography) (EEG) data, plot it, and then create a minimap based on the [z-score](https://en.wikipedia.org/wiki/Standard_score) of the data for easier navigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8109537b-5fba-4f07-aba4-91a56f7e95c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import holoviews as hv\n",
    "from bokeh.models import HoverTool\n",
    "from holoviews.operation.normalization import subcoordinate_group_ranges\n",
    "from holoviews.plotting.links import RangeToolLink\n",
    "from scipy.stats import zscore\n",
    "\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c95f241-2314-42b0-b6cb-2c0baf332686",
   "metadata": {},
   "source": [
    "## Generating EEG data\n",
    "\n",
    "Let's start by simulating some EEG data. We'll create a timeseries for each channel using sine waves with varying frequencies. We'll have two groups *A* and *B* of timeseries that have different amplitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac3812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "from holoviews.operation.normalization import subcoordinate_group_ranges\n",
    "from holoviews.plotting.links import RangeToolLink\n",
    "from scipy.stats import zscore\n",
    "\n",
    "hv.extension('bokeh')\n",
    "\n",
    "GROUP_EEG = 'EEG'\n",
    "GROUP_POS = 'Position'\n",
    "N_CHANNELS_EEG = 10\n",
    "N_CHANNELS_POS = 3\n",
    "N_SECONDS = 5\n",
    "SAMPLING_RATE_EEG = 200\n",
    "SAMPLING_RATE_POS = 25\n",
    "INIT_FREQ = 2  # Initial frequency in Hz\n",
    "FREQ_INC = 5  # Frequency increment\n",
    "AMPLITUDE_EEG = 100  # EEG amplitude in µV\n",
    "AMPLITUDE_POS = 10  # Position amplitude in cm\n",
    "\n",
    "# Generate time for EEG and position data\n",
    "total_samples_eeg = N_SECONDS * SAMPLING_RATE_EEG\n",
    "total_samples_pos = N_SECONDS * SAMPLING_RATE_POS\n",
    "time_eeg = np.linspace(0, N_SECONDS, total_samples_eeg)\n",
    "time_pos = np.linspace(0, N_SECONDS, total_samples_pos)\n",
    "\n",
    "# Generate EEG timeseries data\n",
    "def generate_eeg_data(index):\n",
    "    return AMPLITUDE_EEG * np.sin(2 * np.pi * (INIT_FREQ + index * FREQ_INC) * time_eeg)\n",
    "\n",
    "eeg_channels = np.arange(N_CHANNELS_EEG)\n",
    "eeg_data = np.array([generate_eeg_data(i) for i in eeg_channels])\n",
    "eeg_df = pd.DataFrame(eeg_data.T, index=time_eeg, columns=eeg_channels)\n",
    "eeg_df.index.name = 'Time'\n",
    "\n",
    "# Generate position data\n",
    "pos_channels = ['x', 'y', 'z']\n",
    "pos_data = AMPLITUDE_POS * np.random.randn(N_CHANNELS_POS, total_samples_pos).cumsum(axis=1)\n",
    "pos_df = pd.DataFrame(pos_data.T, index=time_pos, columns=pos_channels)\n",
    "pos_df.index.name = 'Time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bae9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hover tool\n",
    "hover = HoverTool(tooltips=[\n",
    "    (\"Info\", \"@info\"),\n",
    "    (\"Time\", \"$x s\"),\n",
    "    (\"Value\", \"$y\")\n",
    "])\n",
    "\n",
    "hover_tooltips = [\n",
    "    (\"Type\", \"@info\"),\n",
    "    (\"\")\n",
    "    (\"Time\", \"$x s\"),\n",
    "    (\"Value\", \"$y\")\n",
    "]\n",
    "\n",
    "\n",
    "amp_dim = hv.Dimension(\"Amplitude\", unit=\"µV\")\n",
    "time_dim = hv.Dimension(\"Time\", unit=\"s\")\n",
    "\n",
    "# EEG data visualization\n",
    "eeg_curves = []\n",
    "for channel, channel_data in enumerate(eeg_data):\n",
    "    info = f\"EEG {channel}\"\n",
    "    ds = hv.Dataset((channel_data.index, channel_data, info), [time_dim, amp_dim, \"Type\", \"Channel\"])\n",
    "    curve = hv.Curve(ds, time_dim, [amp_dim, \"info\"], group='EEG', label=info)\n",
    "    curve.opts(\n",
    "        subcoordinate_y=True, color=\"black\", line_width=1, hover_tooltips=hover_tooltips,\n",
    "    )\n",
    "    eeg_curves.append(curve)\n",
    "\n",
    "eeg_overlay = hv.Overlay(eeg_curves, kdims=\"Channel\").opts(\n",
    "    xlabel=\"Time (s)\", ylabel=\"Channel\", show_legend=False, aspect=3, responsive=True,\n",
    ")\n",
    "\n",
    "# Position data visualization\n",
    "position_curves = []\n",
    "for i, axis in enumerate(['x', 'y', 'z']):\n",
    "    info = f\"Position {axis.upper()}\"\n",
    "    ds = hv.Dataset((time_pos, pos_data[i], info), [\"Time\", \"Position\", \"info\"])\n",
    "    curve = hv.Curve(ds, \"Time\", [\"Position\", \"info\"], group='Position', label=info)\n",
    "    curve.opts(\n",
    "        subcoordinate_y=True, color=\"blue\", line_width=1, tools=[hover],\n",
    "    )\n",
    "    position_curves.append(curve)\n",
    "\n",
    "position_overlay = hv.Overlay(position_curves, kdims=\"Axis\").opts(\n",
    "    xlabel=\"Time (s)\", ylabel=\"Axis\", show_legend=True, aspect=3, responsive=True,\n",
    ")\n",
    "\n",
    "# Combine EEG and position visualizations\n",
    "combined_overlay = eeg_overlay * position_overlay\n",
    "\n",
    "# Apply group-wise normalization\n",
    "normalized_overlay = subcoordinate_group_ranges(combined_overlay)\n",
    "\n",
    "# Display the dashboard\n",
    "dashboard = normalized_overlay #opts(merge_tools=False)\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8f52ab-3c19-4680-bbf1-8f01017175d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUPS = ['A', 'B']\n",
    "N_CHANNELS_PER_GROUP = {'A': 10, 'B': 5}\n",
    "N_SECONDS = 5\n",
    "SAMPLING_RATE = 200\n",
    "INIT_FREQ = 2  # Initial frequency in Hz\n",
    "FREQ_INC = 5  # Frequency increment\n",
    "AMPLITUDE_PER_GROUP = {'A': 1, 'B': 10}\n",
    "\n",
    "# Generate time and channel labels\n",
    "total_samples = N_SECONDS * SAMPLING_RATE\n",
    "time = np.linspace(0, N_SECONDS, total_samples)\n",
    "channels = {\n",
    "    group: list(range(N_CHANNELS_PER_GROUP[group]))\n",
    "    for group in GROUPS\n",
    "}\n",
    "\n",
    "# Generate timeseries data\n",
    "def channel_data(index, amplitude):\n",
    "    return amplitude * np.sin(2 * np.pi * (INIT_FREQ + index * FREQ_INC) * time)\n",
    "\n",
    "data = {\n",
    "    group: np.array([channel_data(i, AMPLITUDE_PER_GROUP[group]) for i in range(N_CHANNELS_PER_GROUP[group])])\n",
    "    for group in GROUPS\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9e71b8-a995-4c0f-bdbb-5d148d8fa138",
   "metadata": {},
   "source": [
    "## Visualizing EEG Data\n",
    "\n",
    "Next, let's dive into visualizing the EEG data. We construct each timeseries using a `Curve` element, assigning it a `group`, a `label` and setting `subcoordinate_y=True`. All these curves are then aggregated into a list, which serves as the input for an `Overlay` element. Rendering this `Overlay` produces a plot where the timeseries are stacked vertically.\n",
    "\n",
    "Additionally, we'll enhance user interaction by implementing a custom hover tool. This will display key information—channel, time, and amplitude—when you hover over any of the curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9476769f-3935-4236-b010-1511d1a1e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hover = HoverTool(tooltips=[\n",
    "    (\"Info\", \"@info\"),\n",
    "    (\"Time\", \"$x s\"),\n",
    "    (\"Amplitude\", \"$y µV\")\n",
    "])\n",
    "\n",
    "channel_curves = []\n",
    "for group in GROUPS:\n",
    "    for channel, channel_data in zip(channels[group], data[group]):\n",
    "        info = f\"EEG {group} {channel}\"\n",
    "        ds = hv.Dataset((time, channel_data, info), [\"Time\", \"Amplitude\", \"info\"])\n",
    "        curve = hv.Curve(ds, \"Time\", [\"Amplitude\", \"info\"], group=group, label=info)\n",
    "        curve.opts(\n",
    "            subcoordinate_y=True, color=\"black\", line_width=1, tools=[hover],\n",
    "        )\n",
    "        channel_curves.append(curve)\n",
    "\n",
    "eeg = hv.Overlay(channel_curves, kdims=\"Channel\").opts(\n",
    "    xlabel=\"Time (s)\", ylabel=\"Channel\", show_legend=False, aspect=3, responsive=True,\n",
    ")\n",
    "eeg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983e1f84-6006-4d64-9144-4aba0ad93946",
   "metadata": {},
   "source": [
    "Note that the overlay above has two wheel-zoom tools. These tools are automatically attached to the groups *A* and *B*, zooming in and out is scoped to the selected group.\n",
    "\n",
    "By default all the curves are displayed with the same *y* limits, computed over all the available data. As a consequence, timeseries in group *A*, which have a much smaller amplitude than timeseries in group *B*, appear to be quite flat and are hard to inspect. To deal with this situation, we can transform the *Overlay* with the `subcoordinate_group_ranges` operation that will apply a min-max normalization of the timeseries per group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb78a48-5c6a-4969-bf58-539fce784364",
   "metadata": {},
   "outputs": [],
   "source": [
    "neeg = subcoordinate_group_ranges(eeg)\n",
    "neeg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f603e2-039d-421a-ba9a-ed9e77efab99",
   "metadata": {},
   "source": [
    "## Creating the Minimap\n",
    "\n",
    "A minimap can provide a quick overview of the data and help you navigate through it. We'll compute the z-score for each channel and represent it as an image; the z-score will normalize the data and bring out the patterns more clearly. To enable linking in the next step between the EEG `Overlay` and the minimap `Image`, we ensure they share the same y-axis range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fa2198-c3b5-41e1-944f-f8b812612168",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_positions = range(sum(N_CHANNELS_PER_GROUP.values()))\n",
    "yticks = list(enumerate([f\"EEG {group} {channel}\" for group in channels for channel in channels[group]]))\n",
    "\n",
    "z_data = zscore(np.concatenate(list(data.values())), axis=1)\n",
    "\n",
    "minimap = hv.Image((time, y_positions , z_data), [\"Time (s)\", \"Channel\"], \"Amplitude (uV)\")\n",
    "minimap = minimap.opts(\n",
    "    cmap=\"RdBu_r\", xlabel='Time (s)', alpha=.5, yticks=[yticks[0], yticks[-1]],\n",
    "    height=150, responsive=True, default_tools=[], clim=(-z_data.std(), z_data.std())\n",
    ")\n",
    "minimap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b77970-342f-4428-bd1c-4dbef1e6a2b5",
   "metadata": {},
   "source": [
    "## Building the dashboard\n",
    "\n",
    "Finally, we use [`RangeToolLink`](../../../user_guide/Linking_Plots.ipynb) to connect the minimap `Image` and the EEG `Overlay`, setting bounds for the initially viewable area with `boundsx` and `boundsy`, and finally a max range of 2 seconds with `intervalsx`. Once the plots are linked and assembled into a unified dashboard, you can interact with it. Experiment by dragging the selection box on the minimap or resizing it by clicking and dragging its edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260489eb-2dbf-4c88-ba83-dd1cba0e547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RangeToolLink(\n",
    "    minimap, neeg, axes=[\"x\", \"y\"],\n",
    "    boundsx=(None, 2), boundsy=(None, 6.5),\n",
    "    intervalsx=(None, 2),\n",
    ")\n",
    "\n",
    "dashboard = (neeg + minimap).opts(merge_tools=False).cols(1)\n",
    "dashboard"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
