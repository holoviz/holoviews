{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Streaming Data\n",
    "\n",
    "\"Streaming data\" is data that is continuously generated, often by some external source like a remote website, a measuring device, or a simulator. This kind of data is common for financial time series, web server logs,  scientific applications, and many other situations. \n",
    "\n",
    "The HoloViews ``Stream`` system provides a way to push arbitrary content to a ``DynamicMap`` callback, constructing a plot that updates over time.  This system was already discussed in the user guide sections [Responding to Events](11-Responding_to_Events.ipynb) and [Custom Interactivity](12-Custom_Interactivity.ipynb), but those examples showed streaming changes to plot metadata like zoom ranges, not to the underlying data.  Here, we will show how the HoloViews ``DataStream`` and ``DataFrameStream`` streams can be used to work with streaming *data sources* as well. Apart from streaming directly in HoloViews we will also explore working with streaming data coordinated by the separate [``streamz``](http://matthewrocklin.com/blog/work/2017/10/16/streaming-dataframes-1) library from Matt Rocklin, which makes working with complex streaming pipelines much simpler.\n",
    "\n",
    "*NOTE: To follow along with how it works, this example should be run one cell at a time in a Jupyter notebook.  Viewing a static copy from a website or the result of \"Run All\" will not show the dynamic updates provided by streaming.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "\n",
    "from holoviews.streams import DataStream, DataFrameStream\n",
    "\n",
    "import streamz\n",
    "import streamz.dataframe\n",
    "\n",
    "# Hide the gifs\n",
    "from IPython.display import display, Javascript\n",
    "display(Javascript(\"$('img.gif').hide()\"))\n",
    "\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataStream\n",
    "\n",
    "A ``DataStream`` allows data to be pushed into a DynamicMap callback to change a visualization, just like the streams in the [Responding to Events](./11-Responding_to_Events.ipynb) user guide were used to push changes to metadata that controlled the visualization.\n",
    "\n",
    "Let's start with a fairly simple example:\n",
    "1. Declare a ``streamz.Stream`` and a ``hv.streams.DataStream`` object and connect them into a pipeline into which we can push data. \n",
    "2. Use a ``sliding_window`` of 10, which will first wait for 10 sets of stream updates to accumulate. At that point and for every subsequent update, it will apply ``pd.concat`` to combine the most recent 10 updates into a new dataframe. \n",
    "3. Use the ``sink`` method on the ``Stream`` to ``send`` the resulting collection of 10 updates to ``DataStream``.\n",
    "4. Declare a ``DynamicMap`` that takes the sliding window of concatenated DataFrames and displays it using a ``Scatter`` Element.\n",
    "5. Color the ``Scatter`` points by their 'count' and set a range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_source = streamz.Stream()\n",
    "stream_data = hv.streams.DataStream(data=[])\n",
    "point_source.sliding_window(20).map(pd.concat).sink(stream_data.send)\n",
    "opts = dict(color_index='count', bgcolor='black')\n",
    "hv.DynamicMap(hv.Scatter, streams=[stream_data]).opts(plot=opts).redim.range(y=(-4, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img class=\"gif\" src=\"http://assets.holoviews.org/gifs/guides/user_guide/Streaming_Data/streamz1.gif\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is now a pipeline, but initially this plot will be empty, because no data has been sent to it. To see the plot update, let's use ``stream.emit`` and send small chunks of random pandas DataFrames to our plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "    point_source.emit(pd.DataFrame({'x': np.random.rand(100), 'y': np.random.randn(100), 'count': i},\n",
    "                                   columns=['x', 'y', 'count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above cell is run, you should see the previous plot update 100 times, and then stop on the last update.  Hopefully this example makes clear how data can get pushed into an existing plot.\n",
    "\n",
    "#### Asynchronous updates\n",
    "\n",
    "In most cases, instead of pushing Stream updates manually from the same Python process, you'll want the object to update asynchronously as new data arrives. Since both Jupyter and Bokeh server run on Tornado, we can use the tornado ``IOLoop`` in both cases to define a non-blocking co-routine that can push data to our stream whenever it is ready. In this case we will use the ``rate_limit`` method to limit how quickly events are emitted.  We'll also emit NumPy arrays rather than dataframes, and then accumulate in a ``sliding_window`` and concatenate as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve [width=600] {+framewise}\n",
    "from tornado.ioloop import IOLoop\n",
    "from tornado import gen\n",
    "\n",
    "curve_source = streamz.Stream(asynchronous=True)  # tell the stream we're working asynchronously\n",
    "stream_data = DataStream(data=[])\n",
    "curve_source.rate_limit(0.1).sink(stream_data.send)\n",
    "\n",
    "@gen.coroutine\n",
    "def f():\n",
    "    for x in range(100):\n",
    "        yield curve_source.emit(np.random.rand(100))\n",
    "        \n",
    "IOLoop.current().add_callback(f)\n",
    "hv.DynamicMap(hv.Curve, streams=[stream_data]).redim.range(y=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img class=\"gif\" src=\"http://assets.holoviews.org/gifs/guides/user_guide/Streaming_Data/streamz2.gif\" width=600px></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the plot should update 100 times as before, but now via the Tornado IOLoop which will not block other interactions and work in the notebook.\n",
    "\n",
    "## StreamingDataFrame\n",
    "\n",
    "While ``DataStream`` provides a general solution for piping arbitrary data to ``DynamicMap`` callback, the ``hv.stream.DataFrameStream`` provides a very powerful means of working with streaming Pandas dataframes with or without the ``streamz`` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``DataFrameStream`` accepts regular pandas DataFrames or streamz DataFrames and Series. We will start with a simple example using just a pandas DataFrame. To initialize a ``DataFrameStream`` we have to provide an example DataFrame, which defines the columns and dtypes of the data we will be streaming. We can also specify whether we will also want to use the ``DataFrame`` ``index``. In this case we will simply define that we want to plot a ``DataFrame`` of x and y positions as a set of ``Points`` and a ``Curve``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = pd.DataFrame({'x': [], 'y': [], 'count': []}, columns=['x', 'y', 'count'])\n",
    "dfstream = DataFrameStream(example, index=False, backlog=100)\n",
    "hv.DynamicMap(hv.Curve, streams=[dfstream]).opts(style=dict(line_width=1, color='black')) *\\\n",
    "hv.DynamicMap(hv.Points, streams=[dfstream]).opts(plot=dict(color_index='count'),\n",
    "                                                  style=dict(line_color='black', size=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img class=\"gif\" src=\"http://assets.holoviews.org/gifs/guides/user_guide/Streaming_Data/brownian.gif\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have set up the ``DataFrameStream`` and defined a ``DynamicMap`` to plot the data we can start pushing data to it. We will define a simple function which simulates brownian motion throughWe can ``send`` data through the ``hv.streams.DataFrameStream`` directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = 0, 0\n",
    "def gen_brownian(i):\n",
    "    global x, y\n",
    "    x += np.random.randn()\n",
    "    y += np.random.randn()\n",
    "    return pd.DataFrame([(x, y, i)], columns=['x', 'y', 'count'])\n",
    "\n",
    "for i in range(200):\n",
    "    dfstream.send(gen_brownian(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfstream.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### A simple streamz example\n",
    "\n",
    "The ``streamz.dataframe`` module provides a ``Random`` utility that generates a ``StreamingDataFrame`` emitting data with a certain frequency at a specified interval. The ``example`` attribute lets us see the structure and dtypes of the data we can expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_sdf = streamz.dataframe.Random(freq='10ms', interval='100ms')\n",
    "print(simple_sdf.index)\n",
    "simple_sdf.example.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the ``StreamingDataFrame`` provides a pandas-like API, we can specify operations on the data directly. In this example we subtract a fixed offset and then compute the cumulative sum, giving us a randomly drifting timeseries. We can then pass the x-values of this dataframe to the HoloViews ``DataFrameStream`` and supply ``hv.Curve`` as the ``DynamicMap`` callback to stream the data into a HoloViews ``Curve``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve [width=500 show_grid=True]\n",
    "sdf = (simple_sdf-0.5).cumsum()\n",
    "hv.DynamicMap(hv.Curve, streams=[DataFrameStream(sdf.x)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img class=\"gif\" src=\"http://assets.holoviews.org/gifs/guides/user_guide/Streaming_Data/streamz3.gif\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``Random`` StreamingDataFrame will asynchronously emit events until it is stopped, which we can do by calling the ``stop`` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_sdf.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making use of the StreamingDataFrame API\n",
    "\n",
    "So far we have only computed the cumulative sum, but the ``StreamingDataFrame`` actually has an extensive API that lets us run a broad range of streaming computations on our data. For example, let's apply a rolling mean to our x-values with a window of 500ms and overlay it on top of the 'raw' data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve [width=500 show_grid=True]\n",
    "source_df = streamz.dataframe.Random(freq='5ms', interval='100ms')\n",
    "sdf = (source_df-0.5).cumsum()\n",
    "hv.DynamicMap(hv.Curve, streams=[DataFrameStream(sdf.x)]).relabel('raw') *\\\n",
    "hv.DynamicMap(hv.Curve, streams=[DataFrameStream(sdf.x.rolling('500ms').mean())]).relabel('smooth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img class=\"gif\" src=\"http://assets.holoviews.org/gifs/guides/user_guide/Streaming_Data/streamz4.gif\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_df.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Controlling the backlog\n",
    "\n",
    "By default the ``DataFrameStream`` accumulates a ``backlog`` of 1000 samples. In many cases this is overkill, but we can specify a shorter (or longer) backlog value to control how much history we accumulate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_source = streamz.dataframe.Random(freq='5ms', interval='100ms')\n",
    "sdf = (multi_source-0.5).cumsum()\n",
    "hv.DynamicMap(hv.Table, streams=[DataFrameStream(sdf.x, backlog=10)]) +\\\n",
    "hv.DynamicMap(lambda data: hv.BoxWhisker(data, [], 'x'), streams=[DataFrameStream(sdf.x, backlog=100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img class=\"gif\" src=\"http://assets.holoviews.org/gifs/guides/user_guide/Streaming_Data/streamz5.gif\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the given stream ``sdf`` is being consumed by a table showing a short backlog (where only the items visible in the table need to be kept), along with a plot computing averages and variances over a longer backlog (100 items).\n",
    "\n",
    "#### Updating multiple cells\n",
    "\n",
    "Since a ``StreamingDataFrame`` will emit data until it is stopped, we can subscribe multiple plots across different cells to the same stream.  Here, let's add a ``Scatter`` plot of the same data stream as in the preceding cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.DynamicMap(hv.Scatter, streams=[DataFrameStream(sdf.x)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img class=\"gif\" src=\"http://assets.holoviews.org/gifs/guides/user_guide/Streaming_Data/streamz6.gif\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopping the stream will now stop updates to all three of these DynamicMaps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_source.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying operations\n",
    "\n",
    "As we discovered above, the ``DataFrameStream`` lets us define a backlog window defining how many samples we want to accumulate. We can use this to our advantage and apply an operation over this backlog window. In this example we declare a ``Dataset`` and then apply the ``histogram`` operation to compute a ``Histogram`` over the specified ``backlog`` window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_source = streamz.dataframe.Random(freq='5ms', interval='100ms')\n",
    "sdf = (hist_source-0.5).cumsum()\n",
    "dmap = hv.DynamicMap(hv.Dataset, streams=[DataFrameStream(sdf.x, backlog=500)])\n",
    "hv.operation.histogram(dmap, dimension='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img class=\"gif\" src=\"http://assets.holoviews.org/gifs/guides/user_guide/Streaming_Data/streamz7.gif\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_source.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datashading\n",
    "\n",
    "The same approach will also work for the datashader operation letting us datashade the entire ``backlog`` window even if we make it very large such as 1 million samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts RGB [width=600]\n",
    "from holoviews.operation.datashader import datashade\n",
    "from bokeh.palettes import Blues8\n",
    "large_source = streamz.dataframe.Random(freq='100us', interval='200ms')\n",
    "sdf = (large_source-0.5).cumsum()\n",
    "dmap = hv.DynamicMap(hv.Curve, streams=[DataFrameStream(sdf.x, backlog=1000000)])\n",
    "datashade(dmap, streams=[hv.streams.PlotSize], normalization='linear', cmap=Blues8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img class=\"gif\" src=\"http://assets.holoviews.org/gifs/guides/user_guide/Streaming_Data/streamz8.gif\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_source.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A real example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we will round this guide off with a real example. We will set up a DataFrameStream emitting data about CPU and memory usage obtained using the ``psutil`` library. You can install ``psutil`` with ``pip install psutil`` or ``conda install psutil``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "from tornado.ioloop import IOLoop\n",
    "from tornado import gen\n",
    "\n",
    "################################################\n",
    "# Define functions to get memory and CPU usage #\n",
    "################################################\n",
    "\n",
    "def get_mem_data():\n",
    "    vmem = psutil.virtual_memory()\n",
    "    df = pd.DataFrame(dict(free=vmem.free/vmem.total,\n",
    "                           used=vmem.used/vmem.total),\n",
    "                      index=[pd.Timestamp.now()])\n",
    "    return df*100\n",
    "\n",
    "def get_cpu_data():\n",
    "    cpu_percent = psutil.cpu_percent(percpu=True)\n",
    "    df = pd.DataFrame(list(enumerate(cpu_percent)), columns=['CPU', 'Utilization'])\n",
    "    df['time'] = pd.Timestamp.now()\n",
    "    return df\n",
    "\n",
    "##################################################\n",
    "# Define DynamicMap callbacks returning Elements #\n",
    "##################################################\n",
    "\n",
    "def mem_stack(data):\n",
    "    data = pd.melt(data, 'index', var_name='Type', value_name='Usage')\n",
    "    areas = hv.Dataset(data).to(hv.Area, 'index', 'Usage')\n",
    "    return hv.Area.stack(areas.overlay()).relabel('Memory')\n",
    "\n",
    "def cpu_box(data):\n",
    "    return hv.BoxWhisker(data, 'CPU', 'Utilization').relabel('CPU Usage')\n",
    "\n",
    "\n",
    "####################################################\n",
    "# Set up StreamingDataFrame and add async callback #\n",
    "####################################################\n",
    "\n",
    "cpu_stream = DataFrameStream(get_cpu_data(), 800)\n",
    "mem_stream = DataFrameStream(get_mem_data())\n",
    "\n",
    "@gen.coroutine\n",
    "def f():\n",
    "    for i in range(500):\n",
    "        yield gen.sleep(0.01)\n",
    "        yield cpu_stream.send(get_cpu_data())\n",
    "        yield mem_stream.send(get_mem_data())\n",
    "\n",
    "IOLoop.current().add_callback(f)\n",
    "\n",
    "#######################################\n",
    "# Define DynamicMaps and display plot #\n",
    "#######################################\n",
    "\n",
    "cpu_dmap = hv.DynamicMap(cpu_box, streams=[cpu_stream])\n",
    "mem_dmap = hv.DynamicMap(mem_stack, streams=[mem_stream])\n",
    "\n",
    "opts = {'plot': dict(width=500, height=400, color_index='CPU'),\n",
    "        'style': dict(box_fill_color=hv.Cycle('Category20'))}\n",
    "\n",
    "(cpu_dmap.redim.range(Utilization=(0, 100)).opts(**opts) +\n",
    " mem_dmap.redim.range(Usage=(0, 100)).opts(plot=dict(height=400, width=400)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img class=\"gif\" src=\"http://assets.holoviews.org/gifs/guides/user_guide/Streaming_Data/streamz9.gif\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, streaming data works like streams in HoloViews in general, flexibly handling changes over time under either explicit control or governed by some external data source."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
